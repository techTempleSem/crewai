{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ[\"SERPER_API_KEY\"]=SERPER_API_KEY\n",
    "os.environ['OPENAI_API_KEY']=OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AkUXc9z8DZSf9Uvj5fVZ5khSihQdW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='2002년 월드컵 4강에는 독일, 브라질, 터키, 한국이 진출했습니다. 이 중에서 브라질이 우승을 차지했습니다. 이웃님한테 도움이 되었길 바랍니다.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1735643852, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=90, prompt_tokens=31, total_tokens=121, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"2002년 월드컵 4강 국가 알려줘\"\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 AI 언어 모델로, 다양한 질문에 답하거나 정보를 제공하는 역할을 합니다. 여러분의 궁금증을 해결하고, 대화를 나누며 도움을 드릴 수 있어요. 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 17, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None}, id='run-c4ee3604-e042-4281-af69-217af497a940-0', usage_metadata={'input_tokens': 17, 'output_tokens': 53, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat=ChatOpenAI(\n",
    "    model_name='gpt-4o-mini'\n",
    ")\n",
    "chat.invoke(\"안녕~ 너를 소개해 줄래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['개수', '재료'], input_types={}, partial_variables={}, template='\\n        너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 {개수}개 추천하고,\\n        그 요리의 레시피를 제시해 줘. 내가 가진 재료는 아래와 같아.\\n        <재료>\\n        {재료}\\n        ')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 {개수}개 추천하고,\n",
    "        그 요리의 레시피를 제시해 줘. 내가 가진 재료는 아래와 같아.\n",
    "        <재료>\n",
    "        {재료}\n",
    "        \"\"\"\n",
    "    )\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='\\n        너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 2개 추천하고,\\n        그 요리의 레시피를 제시해 줘. 내가 가진 재료는 아래와 같아.\\n        <재료>\\n        사과, 잼\\n        ')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"개수\": 2, \"재료\": \"사과, 잼\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot. Your name is Bob', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how atr you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thinks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}\"),\n",
    "        (\"human\", \"Hello, how atr you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thinks!\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "message = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the ice cream cone break up with the sundae?\\n\\nBecause it found someone cooler!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain=prompt|model|StrOutputParser()\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't bears wear shoes?  \n",
      "Because they prefer bear feet!"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "prompt=ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "chain = prompt|model\n",
    "\n",
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"['다크 나이트', '존 윅', '매드 맥스: 분노의 도로']\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 73, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-87b7e8af-f085-4600-91fb-dc9dba27c864-0', usage_metadata={'input_tokens': 73, 'output_tokens': 25, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chat_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\"너는 영화 전문가 AI야. 사용자가 원하는 장르의 영화를 리스트 형태로 추천해줘. ex. Query: SF 영화 3개를 추천해 줘/ 답변: ['인터스텔라', '스페이스오디세이','혹성탈출']\")\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "    ]\n",
    ")\n",
    "chain=chat_template|llm\n",
    "chain.invoke(\"액션\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사이코', '엑소시스트', '할로윈', '더 링', '컨저링', '귀신이 산다', '피라냐', '노웨어', '저주', '13일의 금요일']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"List {subject}. answer in Korean \\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "chain.invoke({\"subject\": \"공포 영화\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'continent': 'South America', 'population': '45195777'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class Country(BaseModel):\n",
    "    continent: str = Field(description=\"사용자가 물어본 나라가 속한 대륙\")\n",
    "    population: str = Field(description=\"사용자가 물어본 나라의 인구(int 형식)\")\n",
    "\n",
    "parser=JsonOutputParser(pydantic_object=Country)\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain=prompt|model|parser\n",
    "\n",
    "country_query = \"아르헨티나는 어떤 나라야?\"\n",
    "chain.invoke({\"query\": country_query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
