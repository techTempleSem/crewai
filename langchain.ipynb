{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ[\"SERPER_API_KEY\"]=SERPER_API_KEY\n",
    "os.environ['OPENAI_API_KEY']=OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"2002년 월드컵 4강 국가 알려줘\"\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat=ChatOpenAI(\n",
    "    model_name='gpt-4o-mini'\n",
    ")\n",
    "chat.invoke(\"안녕~ 너를 소개해 줄래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 {개수}개 추천하고,\n",
    "        그 요리의 레시피를 제시해 줘. 내가 가진 재료는 아래와 같아.\n",
    "        <재료>\n",
    "        {재료}\n",
    "        \"\"\"\n",
    "    )\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.invoke({\"개수\": 2, \"재료\": \"사과, 잼\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}\"),\n",
    "        (\"human\", \"Hello, how atr you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thinks!\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "message = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain=prompt|model|StrOutputParser()\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "prompt=ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "chain = prompt|model\n",
    "\n",
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chat_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\"너는 영화 전문가 AI야. 사용자가 원하는 장르의 영화를 리스트 형태로 추천해줘. ex. Query: SF 영화 3개를 추천해 줘/ 답변: ['인터스텔라', '스페이스오디세이','혹성탈출']\")\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "    ]\n",
    ")\n",
    "chain=chat_template|llm\n",
    "chain.invoke(\"액션\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"List {subject}. answer in Korean \\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "chain.invoke({\"subject\": \"공포 영화\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class Country(BaseModel):\n",
    "    continent: str = Field(description=\"사용자가 물어본 나라가 속한 대륙\")\n",
    "    population: str = Field(description=\"사용자가 물어본 나라의 인구(int 형식)\")\n",
    "\n",
    "parser=JsonOutputParser(pydantic_object=Country)\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain=prompt|model|parser\n",
    "\n",
    "country_query = \"아르헨티나는 어떤 나라야?\"\n",
    "chain.invoke({\"query\": country_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "RunnablePassthrough().invoke(\"안녕하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\"\"\"다음 한글 문장을 프랑스어로 번역해 줘: {sentence}\n",
    "                                        French sentence: (print from here)\"\"\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "runnable_chain = {\"sentence\": RunnablePassthrough()}|prompt|model|output_parser\n",
    "runnable_chain.invoke({\"sentence\": \"그녀는 매일 아침 책을 읽습니다.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(RunnablePassthrough.assign(mult=lambda x:x[\"num\"]*3)).invoke({\"num\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x:x[\"num\"]*3),\n",
    "    modified=lambda x:x[\"num\"]+1\n",
    ")\n",
    "runnable.invoke({\"num\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_smile(x):\n",
    "    return x+\":)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "add_smile = RunnableLambda(add_smile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "prompt_str = \"{topic}의 역사에 대해 세문장으로 설명해 주세요.\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "model = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "output_parser = StrOutputParser()\n",
    "chain=prompt|model|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def add_thank(x):\n",
    "    return x+\"들어주셔서 감사합니다:)\"\n",
    "\n",
    "add_thank = RunnableLambda(add_thank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|model|output_parser|add_thank\n",
    "chain.invoke(\"반도체\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    passed=RunnablePassthrough(),\n",
    "    modified=lambda x:x[\"num\"]+1\n",
    ")\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable=RunnableParallel(\n",
    "    passed=RunnablePassthrough(),\n",
    "    modified=add_thank\n",
    ")\n",
    "runnable.invoke(\"안녕하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o-mini', max_completion_tokens=128, temperature = 0)\n",
    "\n",
    "history_prompt=ChatPromptTemplate.from_template(\"{topic}가 무엇의 약자인지 알려주세요\")\n",
    "celeb_prompt=ChatPromptTemplate.from_template(\"{topic}분야의 유명인사 3명의 이름만 알려주세요\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "history_chain=history_prompt|model|output_parser\n",
    "celeb_chain=celeb_prompt|model|output_parser\n",
    "\n",
    "map_chain=RunnableParallel(history=history_chain, celeb=celeb_chain)\n",
    "result=map_chain.invoke({\"topic\": \"AI\"})\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
